{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESA EO $\\phi$- week 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous part of the session, you have already gained experience in navigating around the Euro Data Cube interface and using **GeoDB**. Now, we are going to show a use case example to demonstrate how you can combine some of what you have learnt with **Sentinel Hub Services**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case Example: Deforestation in the Gran Chaco Region\n",
    "\n",
    "In this Jupyter Notebook we are going to investigate deforestation events happening in the Gran Chaco region that spans across parts of eastern Bolivia, western Paraguay, northern Argentina and a small part of the Brazilian state of Mato Grosso. The region has one of the highest rates of deforestation in the world, mainly linked to the expansion of cattle farming. \n",
    "\n",
    "The following articles provide more context information on the subject: [Deforestation in Argentinaâ€™s Gran Chaco\n",
    "](https://earthobservatory.nasa.gov/images/146731/deforestation-in-argentinas-gran-chaco), [Deforestation in Paraguay](https://earthobservatory.nasa.gov/images/92078/deforestation-in-paraguay), [WWF: Gran Chaco](https://www.worldwildlife.org/places/gran-chaco).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.worldlandtrust.org/wp-content/uploads/2018/05/rs11163_massive_deforestation_photo_credits_oscar_rodas-scr_2-640x474.jpg\">\n",
    "\n",
    "Deforested parcels in the Gran Chaco forest region (credit: John Burton, WLT)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Throughout the following examples we will see how to:\n",
    "\n",
    "- request satellite imagery using the Python wrapper to the Sentinel Hub API service\n",
    "- easily request metadata concerning images over a given area and time frame\n",
    "- extract basic statistical information for a given area and time frame\n",
    "\n",
    "First, we will access the [Global Forest Watch](http://www.globalforestwatch.org/about/) dataset (saved as a GeoDB in EDC) on deforestation in Gran Chaco. The original version can be downloaded [here](https://data.globalforestwatch.org/datasets/gran-chaco-deforestation). The dataset, that runs from 2011 to early 2018, represents deforested areas as polygons, derived manually using 30-meter resolution Landsat images for the 55 scenes that cover the Gran Chaco.\n",
    "\n",
    "To check the temporal and spatial accuracy of the polygons, we will select a small test subset in Paraguay and compare the polygons representing deforestation events in January 2018 to higher resolution Sentinel-2 images. In this section, we will see how to query data using Sentinel Hub's python package, and how to get metadata from the Catalog API to select the correct images without wasting resources/time. \n",
    "\n",
    "We will then show you how to use the brand-new data fusion capabilities of Sentinel Hub services to mitigate the drawbacks of using optical sensors for deforestation detection.\n",
    "\n",
    "Finally, we will investigate the time-series of Sentinel-2 images, deriving NDVI (Normalized Difference Vegetation Index) to see if the deforestation event can be automatically detected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDC\n",
    "from edc import setup_environment_variables\n",
    "from xcube_geodb.core.geodb import GeoDBClient\n",
    "\n",
    "# Sentinel Hub Py\n",
    "from sentinelhub import (SHConfig, BBox, bbox_to_dimensions, CRS, SentinelHubRequest, DataCollection, MimeType, FisRequest)\n",
    "from sentinelhub.geometry import Geometry\n",
    "\n",
    "# Utilities\n",
    "from pathlib import Path\n",
    "from oauthlib.oauth2 import BackendApplicationClient\n",
    "from requests_oauthlib import OAuth2Session\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tarfile\n",
    "\n",
    "# Geographical libraries\n",
    "import geopandas\n",
    "from pyproj import Proj, transform\n",
    "from shapely.geometry import shape, box\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "# Plotting\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import colors\n",
    "import matplotlib.patches as mpatches\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "# Rasterio\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import rasterio.features\n",
    "from scipy.ndimage import morphology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup environment variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several options to set up your Sentinel Hub credentials, depending on how you want to access the services. In this workflow, as we will be working with the `sentinelhub-py` package to run requests in Python, we set up an `SHConfig` object that will take care of identification with the services for us. Therefore, we assign the identification parameters provided by EDC to the `SHConfig` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get identification parameters from EDC\n",
    "setup_environment_variables()\n",
    "\n",
    "# Assign environement variables for later use\n",
    "sh_client_id = %env SH_CLIENT_ID\n",
    "sh_client_secret = %env SH_CLIENT_SECRET\n",
    "sh_instance_id = %env SH_INSTANCE_ID\n",
    "\n",
    "# Setup SH services access\n",
    "config = SHConfig()\n",
    "\n",
    "config.sh_client_id = sh_client_id\n",
    "config.sh_client_secret = sh_client_secret\n",
    "config.instance_id = sh_instance_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we set up access to the GeoDB, using `GeoDBClient` as shown in the previous section of this training session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodb = GeoDBClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request a truecolor image as overview of the selected area\n",
    "\n",
    "Now that the credentials are set up, it is possible to request satellite images.\n",
    "\n",
    "We will start by plotting an overview True Color RBG image from Sentinel-2 of the area that we will be working on.\n",
    "\n",
    "The *Sentinel Hub Process API* will need the following information for a valid request:\n",
    "\n",
    "+ An **AOI** (area of interest): that contains the location's coordinates (polygon or bounding box). The image size is pre-calculated according to the resolution desired.\n",
    "+ **Evalscript** in which you specify the data products and their visualisation\n",
    "+ **Request body** with parameters about the location and time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define coordinates for area of interest and create a bbox object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the coordinates (lower-left, upper right) of our AOI\n",
    "aoi_bbox = [-60.28157336, -21.27560428, -60.12293070, -21.18495133]\n",
    "\n",
    "# Set AOI overview bbox\n",
    "resolution = 10\n",
    "aoi_overview = BBox(bbox=aoi_bbox, crs=CRS.WGS84)  # Make a BBox object of the list of coordinates\n",
    "aoi_overview_size = bbox_to_dimensions(aoi_overview, resolution=resolution)  # Automatically calculate the output size in px\n",
    "\n",
    "print(f\"Output image size: {aoi_overview_size[0]} * {aoi_overview_size[1]} px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalscript creation\n",
    "\n",
    "An [Evalscript](https://docs.sentinel-hub.com/api/latest/evalscript/v3/) is a piece of Javascript code that allows you to define the input and output parameters of the data you would like to query, as well as specifying the processing to be applied to the satellite images.\n",
    "\n",
    "For the evalscript you must specify at least the two following functions:\n",
    "\n",
    "+ setup function: this sets up the input (i.e. which bands to call) and output settings (number of bands to return, format, etc...).\n",
    "+ evaluatePixel function - this function is where you specify the processing (to derive new information from the images, or for visualisation) to be applied to the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following Evalscript, we want to return an RGB True Color image. In the `setup` function, we will specify that we want to use the Red (`B04`), Green (`B03`) and Blue (`B02`) bands of Sentinel-2. Since we want a three-channel image (RGB), we specify that our output will have three bands. We use the convenient `AUTO` sample type for the returned data, as we are just going to visualise it. With `AUTO` values should range from 0-1, which will then automatically be stretched from the interval [0, 1] to [0, 255] and written into a UINT8 raster.\n",
    "\n",
    "Because the image would be too dark if we return directly the band values scaled from 0 to 255, we apply a gain (multiplying the values by 3.5). This is just for visualisation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalscript_true_color = \"\"\"\n",
    "//VERSION=3\n",
    "\n",
    "// Set up the input and output settings\n",
    "\n",
    "function setup() {\n",
    "  return {\n",
    "    input: [\"B02\", \"B03\", \"B04\"],  //define input bands\n",
    "    output: { bands: 3, sampleType: SampleType.AUTO}  //define amount of channels in output image (RGB = 3)\n",
    "  };\n",
    "}\n",
    "\n",
    "// Map the input bands to the values in the output raster\n",
    "\n",
    "function evaluatePixel(sample) {\n",
    "  let gain = 3.5;\n",
    "  return [gain * sample.B04, gain * sample.B03, gain * sample.B02];    //map bands 4, 3, 2 to RGB channels and multiply by 3.5 for enhanced truecolor visualisation\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request body creation\n",
    "\n",
    "The run the Evalscript, we need to define the payload, or data parameters to send to Sentinel Hub Services. The Sentinel Hub python package simplifies the writing of the payload, by using the `SentinelHubRequest` class to pass the following input parameters:\n",
    "\n",
    "1. the created evalscript\n",
    "2. input data (data source and time interval)\n",
    "3. define the output (name and format)\n",
    "4. define bbox\n",
    "5. size of the requested image\n",
    "6. identification with the SHConfig object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = SentinelHubRequest(evalscript=evalscript_true_color,\n",
    "                             input_data=[SentinelHubRequest.input_data(data_collection=DataCollection.SENTINEL2_L2A,\n",
    "                                                                       time_interval=(\"2017-12-31\",\n",
    "                                                                                      \"2017-12-31\"))],\n",
    "                            responses=[SentinelHubRequest.output_response('default', MimeType.TIFF)],\n",
    "                            bbox=aoi_overview,  \n",
    "                            size=aoi_overview_size,\n",
    "                            config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the request is created, we just need to run it using the `get_data` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview = request.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the requested image\n",
    "\n",
    "By using `get_data` without any additional parameters saved the results to the `overview` variable. Let's plot it to look at the returned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15,10))\n",
    "ax.imshow(overview[0])\n",
    "\n",
    "# Plot configuration\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_title(\"2017-12-31\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quizz: can you figure out how to request a falsecolor infrared image?\n",
    "Try to fill in the gaps in the evalscript below.\n",
    "\n",
    "*Hint: To receive a falsecolor infrared image you need to map Sentinel-2 Band 8 (NIR) to the red channel, Band 4 (RED) to the green channel, and Band 3 (GREEN) to the blue channel*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalscript_false_color = \"\"\"\n",
    "//VERSION=3\n",
    "\n",
    "function setup() {\n",
    "  return {\n",
    "    input: [\"\", \"\", \"\"],\n",
    "    output: { bands: 3 }\n",
    "  };\n",
    "}\n",
    "\n",
    "function evaluatePixel(sample) {\n",
    "  let gain = 2.5;\n",
    "  return [ , , ];\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the following cell for the solution. Make sure to run the following cell twice, one time for fetching the solution and a second time for running the Evalscript.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load https://raw.githubusercontent.com/sentinel-hub/code-snippets/master/phiweek2020/Solution.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the Evalscript, let's run the request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = SentinelHubRequest(evalscript=evalscript_false_color,\n",
    "                             input_data=[SentinelHubRequest.input_data(data_collection=DataCollection.SENTINEL2_L2A,\n",
    "                                                                       time_interval=(\"2017-12-31\",\n",
    "                                                                                      \"2017-12-31\"))],\n",
    "                            responses=[SentinelHubRequest.output_response('default', MimeType.TIFF)],\n",
    "                            bbox=aoi_overview,  \n",
    "                            size=aoi_overview_size,\n",
    "                            config=config)\n",
    "\n",
    "overview_fc = request.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the False Color image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15,10))\n",
    "ax.imshow(overview_fc[0])\n",
    "\n",
    "# Plot configuration\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_title(\"2017-12-31\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the collection from GeoDB and data preparation\n",
    "In the next step we retrieve the prepared gran_chaco collection from GeoDB.\n",
    "\n",
    "As a reminder, you can explore the original dataset [here](https://data.globalforestwatch.org/datasets/gran-chaco-deforestation/data?geometry=-60.601%2C-20.023%2C-59.293%2C-19.797)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check available collections in GeoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `geodb` client, let's look at what collections are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets get already existing collections\n",
    "geodb.get_my_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the collection by bbox to retrieve only the area we are interested in\n",
    "\n",
    "We are interested in the `gran_chaco` GeoDB collection. However, we will not query it entirely in this exercise since we are only interested in a specific AOI that we defined further up. Therefore, not needing the whole dataset, we only retrieve the polygons that are contained in our area of interest by querying the dataset with our defined bbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gran_chaco = geodb.get_collection_by_bbox('gran_chaco', database=\"phi_week\", bbox=aoi_bbox, bbox_crs=4326, comparison_mode=\"contains\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's preview the collection subset that we have just queried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gran_chaco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "\n",
    "As we can see above, in the subset of the GeoDB that we queried, there are deforestation events detected in 2011, 2014, 2015, 2016, 2017 and 2018. Let's narrow down the dataset a little further and only select the polygons in 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we convert the date strings to `datetime` objects to make the querying easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dates to datetime objects and store in a new column\n",
    "gran_chaco[\"datetime\"] = pd.to_datetime(gran_chaco[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only polygons from 2018\n",
    "gran_chaco_subset_2018 = gran_chaco[gran_chaco[\"datetime\"].dt.year == 2018]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can preview the subset that we have selected based on the year 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gran_chaco_subset_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all selected polygons\n",
    "IPython.display.GeoJSON(gran_chaco_subset_2018.__geo_interface__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fun fact: thanks to Ipython, it is easy to zoom out to have an idea of the location of the polygons. Furthermore, you can click on an individual polygon to list the attributes of that specific shape in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Catalog API for dates with  available Sentinel-2 data before and after the registered deforestation event\n",
    "\n",
    "For our selected AOI, we will check if the registered deforestation date in the dataset that we are querying is correct. To do so, we will look at the closest cloud-free Sentinel images before and after the date assigned to the polygon (here, `2018-01-31`).\n",
    "\n",
    "Rather than query all the Sentinel-2 images in a given period around the date of interest, which would be a waste of resources particularly in cloudy areas, we can use the Catalog API service to list metadata about the images that will guide our choice in the selection. The Catalog service allows us to return the dates of images intersecting the AOI, but other essential parameters, such as the scene's overall cloud cover."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an OAuth2 session and create a token for it\n",
    "In order to send a request to the Catalog API we need to create a token first. Let's start by creating an OAuth session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a session\n",
    "client = BackendApplicationClient(client_id=sh_client_id)\n",
    "oauth = OAuth2Session(client=client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The token acts like an ID we provide the API with to verify us as a registered user. This token is temporary (about 1h) for security reasons. If when running a Catalog request an authentification error is thrown, just execute the following cell again to obtain a new token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get token for the session\n",
    "token = oauth.fetch_token(token_url='https://services.sentinel-hub.com/oauth/token',\n",
    "                          client_id=sh_client_id, client_secret=sh_client_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Catalog API request\n",
    "We specify the service endpoint URL, set the Content-Type to 'application/json' because we only want to receive a list of dates with available Sentinel-2 data within the selected period. We also set the `collection` that we want to query (here Sentinel-2 L1C), and the time range we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Catalog API url\n",
    "catalog_url = \"https://services.sentinel-hub.com/api/v1/catalog/\"\n",
    "\n",
    "# Set the header\n",
    "headers = {\n",
    "  'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "# Set the Catalog request parameters\n",
    "collections = \"sentinel-2-l1c\"\n",
    "datetime= \"2017-10-01T00:00:00Z/2018-02-15T23:59:59Z\"  # We set a wide time range to get an idea of the available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the catalog request\n",
    "response = oauth.request(\"GET\", f\"https://services.sentinel-hub.com/api/v1/catalog/collections/{collections}/items?bbox={aoi_bbox[0]},{aoi_bbox[1]},{aoi_bbox[2]},{aoi_bbox[3]}&datetime={datetime}&limit=20\", headers=headers)\n",
    "catalog_results = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the dates and cloud cover values\n",
    "available_data = []\n",
    "for entry in catalog_results[\"features\"]:\n",
    "    available_data.append((entry[\"properties\"][\"datetime\"], entry[\"properties\"][\"eo:cloud_cover\"]))\n",
    "    \n",
    "print(available_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter the available dates\n",
    "\n",
    "We now have a list of images and their respective cloud cover available, we can filter out for the closest dates to the deforestation event marked in our database, taking in account the cloud cover. \n",
    "\n",
    "Let's select the images with less than 10% cloud cover over the entire scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the date of interest. Since all the dates are the same in our subset, we take the first one.\n",
    "deforestation_date = dt.strptime(gran_chaco_subset_2018.date.values[0], \"%Y-%m-%d\")\n",
    "\n",
    "# Cloud cover percentage filter\n",
    "cc = 10\n",
    "\n",
    "# We want to select the dates that have less than the set % of cloud cover\n",
    "available_datetimes = [dt.strptime(x[0], \"%Y-%m-%dT%H:%M:%SZ\") for x in available_data if x[1] <= cc]\n",
    "\n",
    "# Find the index before and after our date of interest\n",
    "past_dates = [date for date in available_datetimes if date < deforestation_date]\n",
    "future_dates = [date for date in available_datetimes if date >= deforestation_date]\n",
    "\n",
    "before_ind = available_datetimes.index(max(past_dates))\n",
    "after_ind = available_datetimes.index(min(future_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Closest date with less than {cc}% cloud cover. Before: {available_datetimes[before_ind]}; After: {available_datetimes[after_ind]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Sentinel-2 images\n",
    "\n",
    "Now we have the dates that we are interested in, we will query the images using `sentinelhub-py`, as we did for the True Color and False Color RGB images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we set the bounding box to cover our selected field based on the geometry of the object in the database. We will set a buffer to make sure that we cover the entire set of polygons. Note that the buffer values are in degrees since the coordinates are in `WGS84`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set AOI bounding box for our example polygons and image size according to desired resolution\n",
    "resolution = 10\n",
    "aoi = BBox(bbox=box(*gran_chaco_subset_2018.total_bounds).buffer(0.001).bounds, crs=CRS.WGS84)\n",
    "aoi_size = bbox_to_dimensions(aoi, resolution=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our request, we will do things a little differently from the previous requests. Indeed, to be able to plot the extent of the fields in our image, we need it to be georeferenced. Therefore, using the numpy array returned when calling the request is not sufficient. To get a georeferenced image, we will save the response as a `geotiff` locally, then open it with a geospatial library later (here we will use `rasterio`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make two requests: one for the date before the event, that we selected earlier, and one after. Before each request, we make a directory to save the `geotiff`s and set the `save_data` parameter to `True` in the `get_data` method. Note, make sure that you delete any previous requests in the folders (if they exist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a directory to save the response\n",
    "Path('./results/before').mkdir(parents=True, exist_ok=True)\n",
    "  \n",
    "request = SentinelHubRequest(evalscript=evalscript_true_color,\n",
    "                             input_data=[SentinelHubRequest.input_data(data_collection=DataCollection.SENTINEL2_L2A,\n",
    "                                                                       time_interval=(dt.strftime(available_datetimes[before_ind], \"%Y-%m-%d\"),\n",
    "                                                                                      dt.strftime(available_datetimes[before_ind], \"%Y-%m-%d\")))],\n",
    "                            responses=[SentinelHubRequest.output_response('default', MimeType.TIFF)],\n",
    "                            bbox=aoi,  \n",
    "                            size=aoi_size,\n",
    "                            data_folder='./results/before/',\n",
    "                            config=config)\n",
    "\n",
    "true_color_before = request.get_data(save_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a directory to save the response\n",
    "Path('./results/after').mkdir(parents=True, exist_ok=True)\n",
    "  \n",
    "request = SentinelHubRequest(evalscript=evalscript_true_color,\n",
    "                             input_data=[SentinelHubRequest.input_data(data_collection=DataCollection.SENTINEL2_L2A,\n",
    "                                                                       time_interval=(dt.strftime(available_datetimes[after_ind], \"%Y-%m-%d\"),\n",
    "                                                                                      dt.strftime(available_datetimes[after_ind], \"%Y-%m-%d\")))],\n",
    "                            responses=[SentinelHubRequest.output_response('default', MimeType.TIFF)],\n",
    "                            bbox=aoi,  \n",
    "                            size=aoi_size,\n",
    "                            data_folder='./results/after/',\n",
    "                            config=config)\n",
    "\n",
    "true_color_after = request.get_data(save_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have downloaded the data, let's fetch the path to the resulting `geotiff`s and open them with rasterio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get folder name created\n",
    "fld_a = [f for f in Path(\"./results/before/\").iterdir() if f.is_dir()][0]\n",
    "fld_b = [f for f in Path(\"./results/after/\").iterdir() if f.is_dir()][0]\n",
    "\n",
    "# Open raster with Rasterio\n",
    "raster_before = rasterio.open(str(fld_a.joinpath(\"response.tiff\")))\n",
    "raster_after = rasterio.open(str(fld_b.joinpath(\"response.tiff\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the raster images saved locally and show the outline of the selected polygons in the database\n",
    "\n",
    "Here will plot the georeferenced rasterio rasters and add the parcel outlines over the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, ax1) = plt.subplots(nrows=1, ncols=2, figsize=(18, 10))\n",
    "\n",
    "# Plot images before and after\n",
    "show(raster_before, ax=ax)\n",
    "show(raster_after, ax=ax1)\n",
    "\n",
    "# Plot the field outline over the images\n",
    "gran_chaco_subset_2018.plot(ax=ax, edgecolor=\"red\", facecolor=\"none\", linewidth=2)\n",
    "gran_chaco_subset_2018.plot(ax=ax1, edgecolor=\"red\", facecolor=\"none\", linewidth=2)\n",
    "\n",
    "# Plot configuration\n",
    "for axs in [ax, ax1]:\n",
    "    axs.set_xticks([])\n",
    "    axs.set_yticks([])\n",
    "\n",
    "ax.set_title(dt.strftime(available_datetimes[before_ind], \"%Y-%m-%d\"))\n",
    "ax1.set_title(dt.strftime(available_datetimes[after_ind], \"%Y-%m-%d\"))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the image above, we notice several points:\n",
    "\n",
    "1. For some of the smaller polygons we can see that the deforestation happened between the 31<sup>st</sup> December 2017 and 4<sup>th</sup> February 2018. Due to cloud coverage, we cannot narrow down the date any more. But we will get back to this point later in the process.\n",
    "\n",
    "2. The larger polygons that were identified as deforested in January 2018 in the dataset were already partly deforested in December 2017.\n",
    "\n",
    "3. Certain areas delimited manually based on the Landsat images seems shifted compared to the Sentinel-2 images: i.e. the large polygon top centre. This shift may be due to the difference in resolution or slight geolocalisation differences between the sensors.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with Landsat imagery\n",
    "\n",
    "To see the field delination on a Landsat image, we can query a Landsat image as we did for Sentinel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quizz: what is the easiest way to write an Evalscript for Landsat True Color?\n",
    "\n",
    "Based on Landsat [bands](https://docs.sentinel-hub.com/api/latest/data/landsat-8/) available, how would you return a True Color image using the Evalscript?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalscript_landsat_true_color = \"\"\"\"\"\"\n",
    "\n",
    "# Adjust the image size for the change in resolution\n",
    "aoi_size_landsat = bbox_to_dimensions(aoi, resolution=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the following cell for the solution. Make sure to run the following cell twice, one time for fetching the solution and a second time for running the Evalscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load https://raw.githubusercontent.com/sentinel-hub/code-snippets/master/phiweek2020/Solution2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus question: how would you improve the resolution of the True Color image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalscript_landsat_true_color_improved = \"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the following cell for the solution. Make sure to run the following cell twice, one time for fetching the solution and a second time for running the Evalscript.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load https://raw.githubusercontent.com/sentinel-hub/code-snippets/master/phiweek2020/Solution3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the query (using the Evalscript of your choice) for two dates that were preselected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a directory to save the request\n",
    "Path('./results/landsat/before').mkdir(parents=True, exist_ok=True)\n",
    "  \n",
    "request = SentinelHubRequest(evalscript=evalscript_landsat_true_color,\n",
    "                             input_data=[SentinelHubRequest.input_data(data_collection=DataCollection.LANDSAT8,\n",
    "                                                                       time_interval=(\"2017-12-16\",\n",
    "                                                                                      \"2017-12-16\"))],\n",
    "                            responses=[SentinelHubRequest.output_response('default', MimeType.TIFF)],\n",
    "                            bbox=aoi,  \n",
    "                            size=aoi_size_landsat,\n",
    "                            data_folder='./results/landsat/before',\n",
    "                            config=config)\n",
    "\n",
    "true_color_landsat= request.get_data(save_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a directory to save the request\n",
    "Path('./results/landsat/after').mkdir(parents=True, exist_ok=True)\n",
    "  \n",
    "request = SentinelHubRequest(evalscript=evalscript_landsat_true_color,\n",
    "                             input_data=[SentinelHubRequest.input_data(data_collection=DataCollection.LANDSAT8,\n",
    "                                                                       time_interval=(\"2018-01-17\",\n",
    "                                                                                      \"2018-01-17\"))],\n",
    "                            responses=[SentinelHubRequest.output_response('default', MimeType.TIFF)],\n",
    "                            bbox=aoi,  \n",
    "                            size=aoi_size_landsat,\n",
    "                            data_folder='./results/landsat/after',\n",
    "                            config=config)\n",
    "\n",
    "true_color_landsat= request.get_data(save_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did for Sentinel-2, fetch the latest folder and open the image with Rasterio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get folder name created\n",
    "fld_lb = [f for f in Path(\"./results/landsat/before\").iterdir() if f.is_dir()][0]\n",
    "fld_la = [f for f in Path(\"./results/landsat/after\").iterdir() if f.is_dir()][0]\n",
    "\n",
    "# Open raster with Rasterio\n",
    "raster_landsat_before = rasterio.open(str(fld_lb.joinpath(\"response.tiff\")))\n",
    "raster_landsat_after = rasterio.open(str(fld_la.joinpath(\"response.tiff\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Landsat scene saved locally and show the outline of the selected field in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, ax1) = plt.subplots(nrows=1, ncols=2, figsize=(18, 10))\n",
    "\n",
    "# Plot images before and after\n",
    "show(raster_landsat_before, ax=ax)\n",
    "show(raster_landsat_after, ax=ax1)\n",
    "\n",
    "# Plot the field outline over the images\n",
    "gran_chaco_subset_2018.plot(ax=ax, edgecolor=\"red\", facecolor=\"none\", linewidth=2)\n",
    "gran_chaco_subset_2018.plot(ax=ax1, edgecolor=\"red\", facecolor=\"none\", linewidth=2)\n",
    "\n",
    "# Plot configuration\n",
    "for axs in [ax, ax1]:\n",
    "    axs.set_xticks([])\n",
    "    axs.set_yticks([])\n",
    "\n",
    "ax.set_title(\"2017-12-16\")\n",
    "ax1.set_title(\"2018-01-17\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the Landsat images in December 2017 and January 2018, provides more information on how the polygons were delineated. Indeed, owing to the revisit time of Landsat (14 days) and cloud cover, some of the deforestation events that happened end of December 2017 (as we saw in the Sentinel-2 images) were missed. The Landsat acquisition on 17<sup>th</sup> January 2018 provides more insight into the timing of the deforestation. Nevertheless, two of the polygon were already partly deforested in December 2017, which could mean that the dataset contains operator errors. The images also show that the 31<sup>st</sup> January 2018 indicated in the dataset is an arbitrary date representing the entire month of January."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Filling in the Gaps\" or how to use data fusion to mitigate gaps in optical imagery time series\n",
    "\n",
    "In the previous section, we were able to fetch Sentinel-2 images to observe deforestation events. However, in January all the scenes acquired were completely cloud covered. As a recap, let's just look at cloud cover for that time of year using the previous catalog request.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(18, 10))\n",
    "\n",
    "# Plot the cloud cover for available dates\n",
    "ax.plot([dt.strptime(x[0], \"%Y-%m-%dT%H:%M:%SZ\") for x in available_data], [x[1] for x in available_data], marker='o',\n",
    "        markersize=12, linestyle=\"none\", color=\"black\")\n",
    "\n",
    "# Highlight January\n",
    "ax.fill_between((dt.strptime(\"2018-01-01\", \"%Y-%m-%d\"), dt.strptime(\"2018-01-31\", \"%Y-%m-%d\")), (0,0), (100,100), color=\"red\", alpha=0.3)\n",
    "\n",
    "# Plot 10% level\n",
    "ax.plot([dt.strptime(x[0], \"%Y-%m-%dT%H:%M:%SZ\") for x in available_data], [10 for x in available_data], linestyle=\"--\", linewidth=2, color=\"black\")\n",
    "\n",
    "# Plot configuration\n",
    "ax.set_ylim(0,100)\n",
    "ax.set_ylabel(\"Cloud cover percentage\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also know that the deforestation happened before the 17<sup>th</sup> January 2018, when looking at the Landsat image. But is there any way of checking with another satellite platform that isn't affected by clouds?\n",
    "\n",
    "By combining optical imagery with SAR (Synthetic Aperture Radar), the shortcomings of cloud cover can be (partly) mitigated. In this example, we will use Sentinel-1 images. Although the revisit frequency of Sentinel-1 is similar to Sentinel-2 (approximately 6 days at the equator), the additional data may be used to increase the temporal resolution of time-series regardless of local atmospheric conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datafusion\n",
    "\n",
    "We recently wrote a [blog post](https://medium.com/sentinel-hub/data-fusion-combine-satellite-datasets-to-unlock-new-possibilities-26356c481169) about the new datafusion capabilities of Sentinel Hub services. Here, we will combine Sentinel-2 and Sentinel-1 images to detect deforestation event that happened in January."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will use the Catalog API service again to obtain the list of available Sentinel-1 acquisitions in January 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Catalog API url\n",
    "catalog_url = \"https://services.sentinel-hub.com/api/v1/catalog/\"\n",
    "\n",
    "# Set the header\n",
    "headers = {\n",
    "  'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "# Set the Catalog request parameters\n",
    "collections = \"sentinel-1-grd\"  # This time, we use the Sentinel 1 collection\n",
    "datetime= \"2018-01-01T00:00:00Z/2018-01-31T23:59:59Z\"  # Time range over January 2018\n",
    "\n",
    "# Run the catalog request\n",
    "response = oauth.request(\"GET\", f\"https://services.sentinel-hub.com/api/v1/catalog/collections/{collections}/items?bbox={aoi_bbox[0]},{aoi_bbox[1]},{aoi_bbox[2]},{aoi_bbox[3]}&datetime={datetime}&limit=20\", headers=headers)\n",
    "catalog_results = response.json()\n",
    "\n",
    "# Fetch the dates and write to a list\n",
    "s1_dates = []\n",
    "\n",
    "for entry in catalog_results[\"features\"]:\n",
    "    s1_dates.append(entry[\"properties\"][\"datetime\"])\n",
    "    \n",
    "print(s1_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Catalog service API, we see that there are 6 images available for January 2018.\n",
    "\n",
    "### Evalscript\n",
    "\n",
    "In the following Evalscript we will perform the following steps for each pixel in the image:\n",
    "\n",
    "+ check if the pixel's NDVI (see below) value has dropped between December and February. If it hasn't, we will assume there was no deforestation in January and return the Sentinel-2 True Color RGB.\n",
    "+ if the NDVI has dropped from above 0.4 to below 0.4 (an empirical threshold that we set), we then look at the backscatter between different Sentinel-1 dates.\n",
    "+ if the drop in backscatter from a date to another is larger than a given value (once again empirically determined), then we return a colour according to the date.\n",
    "\n",
    "To perform the operations in the list above, we need:\n",
    "\n",
    "- the closest cloud-free Sentinel-2 image before January\n",
    "- the closest cloud-free Sentinel-2 image after January\n",
    "- all Sentinel-1 images in January"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**NDVI (Normalized difference vegetation index)**\n",
    "\n",
    "_The well known and widely used NDVI is a simple, but effective index for quantifying green vegetation. It normalizes green leaf scattering in Near Infra-red wavelengths with chlorophyll absorption in red wavelengths._\n",
    "\n",
    "_The value range of the NDVI is -1 to 1. Negative values of NDVI (values approaching -1) correspond to water. Values close to zero (-0.1 to 0.1) generally correspond to barren areas of rock, sand, or snow. Low, positive values represent shrub and grassland (approximately 0.2 to 0.4), while high values indicate temperate and tropical rainforests (values approaching 1)._<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we color coded the changes as follows:\n",
    "\n",
    "2018-01-01 -> 2018-01-02 = ORANGE\n",
    "\n",
    "\n",
    "2018-01-02 -> 2018-01-13 = WHITE\n",
    "\n",
    "\n",
    "2018-01-13 -> 2018-01-14 = BLUE\n",
    "\n",
    "\n",
    "2018-01-14 -> 2018-01-25 = GREEN\n",
    "\n",
    "\n",
    "2018-01-25 -> 2018-01-26 = RED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalscript_data_fusion = \"\"\"\n",
    "//VERSION=3\n",
    "\n",
    "function setup (){\n",
    "  return {\n",
    "    input: [\n",
    "      {datasource: \"s1\", bands:[\"VH\"]},\n",
    "      {datasource: \"s2_before\", bands:[\"B02\", \"B03\", \"B04\", \"B08\"]},\n",
    "      {datasource: \"s2_after\", bands:[\"B02\", \"B03\", \"B04\", \"B08\"]}],\n",
    "    output: [\n",
    "      {id: \"default\", bands: 3}\n",
    "    ],\n",
    "    mosaicking: \"ORBIT\"\n",
    "  };\n",
    "}\n",
    "  \n",
    "// visualizes decibels from -20 to 0\n",
    "function toDb(linear) {\n",
    "  // the following commented out lines are simplified below\n",
    "  // var log = 10 * Math.log(linear) / Math.LN10\n",
    "  // var val = Math.max(0, (log + 20) / 20)\n",
    "  return Math.max(0, Math.log(linear) * 0.21714724095 + 1)\n",
    "}\n",
    "  \n",
    "function evaluatePixel(samples, scenes) {\n",
    "\n",
    "  // Get samples from different specified datasources\n",
    "  var s1 = samples.s1;\n",
    "  var s2before = samples.s2_before[0];\n",
    "  var s2after = samples.s2_after[0];\n",
    " \n",
    "  // Calculate NDVI before January and after\n",
    "  let ndvi_before = index(s2before.B08, s2before.B04);\n",
    "  let ndvi_after = index(s2after.B08, s2after.B04);\n",
    "  \n",
    "  // Gain for RGB images\n",
    "  var gain = 3;\n",
    "\n",
    "  // If NDVI drop between dates is more than 0.4, query S1 data,\n",
    "  // otherwise return True Color\n",
    "  if (ndvi_before > 0.4 && ndvi_after < 0.4){\n",
    "  \n",
    "    // Db difference threshold\n",
    "    let threshold_bc = 0.2;\n",
    "      \n",
    "    // Return different dates by color\n",
    "    if (toDb(s1[5].VH) - toDb(s1[4].VH) > threshold_bc){\n",
    "      return[255/255, 153/255, 51/255]\n",
    "    } else if (toDb(s1[4].VH) - toDb(s1[3].VH)  > threshold_bc){\n",
    "      return [255/255, 255/255, 255/255]\n",
    "    } else if (toDb(s1[3].VH) - toDb(s1[2].VH)  > threshold_bc){\n",
    "      return [0, 0, 255/255]\n",
    "    } else if (toDb(s1[2].VH) - toDb(s1[1].VH)  > threshold_bc){\n",
    "      return [0, 255/255, 0]\n",
    "    } else if (toDb(s1[1].VH) - toDb(s1[0].VH)  > threshold_bc){\n",
    "      return [255/255, 0, 0] // RED\n",
    "    } else {\n",
    "      return [s2after.B04 * gain, s2after.B03 * gain, s2after.B02 * gain];\n",
    "    }\n",
    "  } else {\n",
    "    return [s2after.B04 * gain, s2after.B03 * gain, s2after.B02 * gain];\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the request body\n",
    "\n",
    "When calling multiple sources of satellite data, the request body is written slightly differently to a request using a single sensor. In the following request, we need to specify as inputs: the Sentinel-1 images during January, the Sentinel-2 images before and after January. The latter are called as two separate data sources to save the number of images queried.\n",
    "\n",
    "In the input data section we show you two different ways of selecting the input parameters for the different data sources:\n",
    "\n",
    "- as a dictionary, which allows more control over the parameters\n",
    "- as a `SentinelHubRequest.input_data` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = SentinelHubRequest(\n",
    "  evalscript=evalscript_data_fusion,\n",
    "  input_data=[\n",
    "    {'type': 'S1GRD',\n",
    "     \"id\": \"s1\",\n",
    "     \"dataFilter\": {\n",
    "          \"timeRange\": {\n",
    "            \"from\": \"2018-01-01T00:00:00Z\",\n",
    "            \"to\": \"2018-01-31T23:59:59Z\"\n",
    "          }\n",
    "        },\n",
    "     \"processing\": {\n",
    "                    \"orthorectify\": \"true\"\n",
    "                   }\n",
    "    },\n",
    "    SentinelHubRequest.input_data(\n",
    "      data_collection=DataCollection.SENTINEL2_L2A,\n",
    "      time_interval=('2017-12-31', '2017-12-31'),        \n",
    "      other_args = {\"id\":\"s2_before\"}\n",
    "    ),\n",
    "    SentinelHubRequest.input_data(\n",
    "      data_collection=DataCollection.SENTINEL2_L2A,\n",
    "      time_interval=('2018-02-04', '2018-02-04'),        \n",
    "      other_args = {\"id\":\"s2_after\"}\n",
    "    ),\n",
    "    \n",
    "  ],\n",
    "  responses=[\n",
    "    SentinelHubRequest.output_response('default', MimeType.TIFF),\n",
    "    \n",
    "  ],\n",
    "  bbox=aoi,  \n",
    "  size=aoi_size,\n",
    "  config=config\n",
    ")\n",
    "datafusion_results = request.get_data() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the resulting image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(18, 10))\n",
    "\n",
    "# Plot the image\n",
    "ax.imshow(datafusion_results[0])\n",
    "\n",
    "# Plot configuration\n",
    "for axs in [ax, ax1]:\n",
    "    axs.set_xticks([])\n",
    "    axs.set_yticks([])\n",
    "    \n",
    "patches = [mpatches.Patch(color=\"orange\", label=\"2018-01-01 - 2018-01-02\"),\n",
    "           mpatches.Patch(facecolor=\"white\", edgecolor=\"black\", label=\"2018-01-02 - 2018-01-13\") ,\n",
    "           mpatches.Patch(color=\"blue\", label=\"2018-01-13 - 2018-01-14\"),\n",
    "           mpatches.Patch(color=\"lime\", label=\"2018-01-14 - 2018-01-25\"),\n",
    "           mpatches.Patch(color=\"red\", label=\"2018-01-25 - 2018-01-26\")]\n",
    "\n",
    "plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), title=\"Deforestation timing:\", loc=2, borderaxespad=0. )\n",
    "\n",
    "ax.set_title(\"Deforestation detection with Sentinel-1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to the use of datafusion, we have managed to narrow down the date of deforestation, despite the large gap in optical satellite images (cloudless scenes) during January. \n",
    "\n",
    "This approach is useful for a visual analysis of images, but is difficultly scalable. In the next section, we will touch upon the automation of the workflow for deforestation event detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thoughts about automated detection of deforestation events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen previously, the manual delineation of deforested parcels using optical images presents several challenges. Furthermore, the method requires significant efforts and time to be scaled up to larger areas. To investigate the potential of automated detection of deforestation, we will make use of the FIS (Feature Info Service) to extract Sentinel-2 derived variables over a given period.\n",
    "\n",
    "In the following steps, we will query NDVI values over the entire time-series of available Sentinel-2 data to investigate trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we select a test field from our dataset. We choose a field that was fully forested in December 2017 and fully cleared in February 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a test field\n",
    "field = gran_chaco_subset_2018[gran_chaco_subset_2018[\"field_id\"] == 88025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the field\n",
    "IPython.display.GeoJSON(field.__geo_interface__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sentinel Hub Python package also allows to use FIS. In the following steps we will build several requests in order to investigate the data in logical steps.\n",
    "\n",
    "In the first request we will query NDVI for the period `2015-01-01` to `2018-02-14`. The request looks a lot like the `SentinelHubRequest` previously used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request NDVI until February 2018\n",
    "fis_request = FisRequest(layer='NDVI',\n",
    "                         data_collection=DataCollection.SENTINEL2_L1C,\n",
    "                         geometry_list=[Geometry(field.geometry.values[0], crs=CRS.WGS84)],\n",
    "                         time=('2015-01-01', '2018-02-14'),\n",
    "                         resolution='10m',\n",
    "                         data_folder='./data',\n",
    "                         maxcc=0.1,\n",
    "                         config=config\n",
    "                         )\n",
    "ndvi = fis_request.get_data(save_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the results of our first request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIS request returns a list of dictionaries and is difficult to read. To make the results more readable, we created a small function to convert the results to a Pandas Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fis_data_to_dataframe(fis_data):\n",
    "    \"\"\" Creates a DataFrame from list of FIS responses\n",
    "    \"\"\"\n",
    "    COLUMNS = ['date', 'min', 'max', 'mean', 'stDev']\n",
    "    data = []\n",
    "    for fd in fis_data:\n",
    "        for channel, channel_stats in fd.items():\n",
    "            if channel == 'C0':                \n",
    "                for stat in channel_stats:\n",
    "                    row = [dt.strptime(stat['date'], \"%Y-%m-%d\")]\n",
    "                    for column in COLUMNS[1:]:\n",
    "                        row.append(stat['basicStats'][column])\n",
    "                        data.append(row)\n",
    "        \n",
    "    # Save to pandas dataframe and reset index\n",
    "    df = pd.DataFrame(data, columns=COLUMNS).sort_values(['date']).drop_duplicates()\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the FIS results to a dataframe\n",
    "ndvi_df = fis_data_to_dataframe(ndvi)\n",
    "\n",
    "# Drop a date (visually identified as hazy)\n",
    "ndvi_df.drop(ndvi_df.loc[ndvi_df['date']==\"2016-12-01\"].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we plot the results of the first request, nicely formatted in a Pandas Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we build a second request that runs from February 2018 to today, to see how NDVI evolves after deforestation has happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the request after deforestation\n",
    "fis_request = FisRequest(layer='NDVI',\n",
    "                         data_collection=DataCollection.SENTINEL2_L1C,\n",
    "                         geometry_list=[Geometry(field.geometry.values[0], crs=CRS.WGS84)],\n",
    "                         time=('2018-02-14', dt.today()),\n",
    "                         resolution='10m',\n",
    "                         data_folder='./data',\n",
    "                         maxcc=0.05,\n",
    "                         config=config\n",
    "                         )\n",
    "\n",
    "# Run the request\n",
    "ndvi_updated = fis_request.get_data(save_data=False)\n",
    "\n",
    "# Convert the results to a dataframe\n",
    "ndvi_df_updated = fis_data_to_dataframe(ndvi_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are interested in comparing the temporal evolution of NDVI to that of a parcel that was not deforested. To do so, we selected an area that was still forested in September 2020>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We select a parcel of forest of approximately the same size of our field for comparison purposes\n",
    "forest = [ -60.19555112, -21.23150358, -60.18345680, -21.22224216]\n",
    "aoi_forest = BBox(bbox=forest, crs=CRS.WGS84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the request\n",
    "fis_request = FisRequest(layer='NDVI',\n",
    "                         data_collection=DataCollection.SENTINEL2_L1C,\n",
    "                         geometry_list=[aoi_forest],\n",
    "                         time=('2015-01-01', dt.today()),\n",
    "                         resolution='10m',\n",
    "                         maxcc=0.05,\n",
    "                         config=config\n",
    "                         )\n",
    "# Run the request\n",
    "forest_patch = fis_request.get_data(save_data=False)\n",
    "\n",
    "# Convert the results to a dataframe\n",
    "forest_df = fis_data_to_dataframe(forest_patch)\n",
    "\n",
    "# Drop a date (visually identified as hazy)\n",
    "forest_df.drop(forest_df.loc[forest_df['date']==\"2018-09-12\"].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the mean NDVI of the selected field over the date range\n",
    "\n",
    "Now our data is ready, we can plot it in steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timeline(step=1):\n",
    "    \"\"\"Plot timeline.\"\"\"\n",
    "    \n",
    "    # Check step value\n",
    "    if (step < 1 or step >4):\n",
    "        raise ValueError(\"Step out of range 1-4\")\n",
    "        \n",
    "    # Setup subplots\n",
    "    fig = plt.figure(figsize=(18,14))\n",
    "    gs = fig.add_gridspec(2, 2)\n",
    "    ax = fig.add_subplot(gs[1, :])\n",
    "    ax2 = fig.add_subplot(gs[0, 0])\n",
    "    ax2.set_title('gs[1, :-1]')\n",
    "    ax3 = fig.add_subplot(gs[0, 1])\n",
    "    ax3.set_title('gs[1, :-1]')\n",
    "\n",
    "    ###########\n",
    "    # 1. Plot the rasters of the field as a reminder\n",
    "    show(raster_before, ax=ax2)\n",
    "    ax2.set_title(dt.strftime(available_datetimes[before_ind], \"%Y-%m-%d\"))\n",
    "    show(raster_after, ax=ax3)\n",
    "    ax3.set_title(dt.strftime(available_datetimes[after_ind], \"%Y-%m-%d\"))\n",
    "\n",
    "    # 2. Plot the mean NDVI until the deforestation\n",
    "    ndvi_df.plot(x='date', y='mean', ax=ax, linestyle='-', marker='.', label=r\"Mean NDVI of the field $\\pm 1\\sigma$\" )\n",
    "\n",
    "    # Plot the standard deviation as a shaded area\n",
    "    ax.fill_between(ndvi_df.date,\n",
    "                    (ndvi_df[\"mean\"] - ndvi_df[\"stDev\"]),\n",
    "                    (ndvi_df[\"mean\"] + ndvi_df[\"stDev\"]),\n",
    "                    alpha=0.3)\n",
    "\n",
    "    # Highlight before and after dates\n",
    "    ax.scatter([\"2017-12-31\", \"2018-02-04\"], [ndvi_df[ndvi_df[\"date\"]==\"2017-12-31\"][\"mean\"], ndvi_df[ndvi_df[\"date\"]==\"2018-02-04\"][\"mean\"]], marker=\"o\", s=65, color=\"red\")\n",
    "\n",
    "    ###########\n",
    "    if step >= 2:\n",
    "        # 2. Plot period after the identified deforestation event\n",
    "        ndvi_df_updated.plot(x='date', y='mean', ax=ax, linestyle='-', marker='.',\n",
    "                             color=\"indianred\", label=\"Period after deforestation\" )\n",
    "        ax.fill_between(ndvi_df_updated.date, ndvi_df_updated[\"mean\"] - ndvi_df_updated[\"stDev\"],\n",
    "                        ndvi_df_updated[\"mean\"] + ndvi_df_updated[\"stDev\"],\n",
    "                        alpha=0.3, color=\"indianred\")\n",
    "\n",
    "    ###########\n",
    "    if step >= 3:\n",
    "        # 3. Plot dry season months\n",
    "        ax.fill_between((\"2015-08-01\", \"2015-10-30\"), (0,0), (1,1), color=\"lightgrey\", alpha=0.7)\n",
    "        ax.fill_between((\"2016-08-01\", \"2016-10-30\"), (0,0), (1,1), color=\"lightgrey\", alpha=0.7)\n",
    "        ax.fill_between((\"2017-08-01\", \"2017-10-30\"), (0,0), (1,1), color=\"lightgrey\", alpha=0.7)\n",
    "        ax.fill_between((\"2018-08-01\", \"2018-10-30\"), (0,0), (1,1), color=\"lightgrey\", alpha=0.7)\n",
    "        ax.fill_between((\"2019-08-01\", \"2019-10-30\"), (0,0), (1,1), color=\"lightgrey\", alpha=0.7)\n",
    "        ax.fill_between((\"2020-08-01\", \"2020-10-30\"), (0,0), (1,1), color=\"lightgrey\", alpha=0.7)\n",
    "\n",
    "    ###########\n",
    "    if step == 4:\n",
    "        # 4. Plot forest patch NDVI\n",
    "        forest_df.plot(x='date', y='mean', ax=ax, linestyle='-', marker='.', color=\"forestgreen\", label=\"Patch of forest close to AOI\" )\n",
    "    \n",
    "    # Plot configuration\n",
    "    ax.legend()\n",
    "    ax.set_ylabel(\"NDVI\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "    ax.tick_params(axis='both', direction='inout', )\n",
    "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=2))\n",
    "    ax.yaxis.set_major_locator(plt.MultipleLocator(0.1))\n",
    "    ax.yaxis.set_ticks_position(\"both\")\n",
    "\n",
    "    for axs in [ax2, ax3]:\n",
    "        field.plot(ax=axs, edgecolor=\"red\", facecolor=\"none\", linewidth=2)\n",
    "        axs.set_xticks([])\n",
    "        axs.set_yticks([])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the data\n",
    "\n",
    "Plot the time series by changing the `step` parameter incresingly from 1 to 4, and observe the graph at each step>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_timeline(step=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring time-series of satellite imagery with FIS is an easy way to understand the data without having to query dozens of images.\n",
    "\n",
    "What does the time series of data tell us?\n",
    "\n",
    "**Step 1:** \n",
    "\n",
    "The NDVI values have small variations over the years, but we notice a very sharp decrease at the time of the identified deforestation event (before and after deforestation are highlighted in red). Can this drop in NDVI be used to detect deforestation?\n",
    "\n",
    "**Step 2:**\n",
    "\n",
    "When looking at the entire time-series of our field until today, we notice large variations in NDVI, with high values followed by large drops. These trends represent cultivated fields that are harvested and cannot be differentiated from deforestation events.\n",
    "\n",
    "**Step 3:**\n",
    "\n",
    "If we shade the dry season each year, we can see that there is a drop in NDVI for forested areas. Furthermore, the harvesting period also corresponds to the dry season. We also notice more variation in the data outside of the dry season.\n",
    "\n",
    "**Step 4:**\n",
    "\n",
    "By plotting the entire time-series of available Sentinel-2 data for a forested patch close the to the selected field, we can compare trends between forested areas and areas after deforestation then cultivation. We can also see that the drop in NDVI for the forest isn't as pronounced during the dry season than for cultivated fields.\n",
    "\n",
    "\n",
    "This graph, along with the previous plots, can provide hints on how to implement an automated workflow to detect a deforestation event, without confusing deforestation with harvesting. Maybe you have some ideas? If you want to explore the subject in more detail, you can run through the following \"bonus\" section...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**END OF GUIDED TUTORIAL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus example: testing the implementation of an automated deforestation detection method using Sentinel-2 images\n",
    "\n",
    "If you want to continue exploring test cases of Sentinel Hub services in the Euro Data Cube, the following cells show an example workflow that automatically detects deforestation events from Sentinel-2 images.\n",
    "\n",
    "This empirical method was designed to showcase Sentinel hub features and probably only works locally. If you think of a better solution, don't hesitate to implement it and share it with the World through the EDC Marketplace!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDVI comparison before / after a deforestation event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous graph, we have seen that even after a deforestation event, there are periods where the NDVI peaks, and is followed by a sharp drop.\n",
    "\n",
    "First, let's inspect the difference between the maximum NDVI before the know deforestation date, and an other peak later on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the graph we will compare the True Color and NDVI images of the selected field on `2017-12-31` and `2018-11-11`. We start by requesting a True Color RGB and NDVI band in the Evalscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalscript_multi_response = \"\"\"\n",
    "//VERSION=3\n",
    "\n",
    "function setup() {\n",
    "  return {\n",
    "    input: [\"B02\", \"B03\", \"B04\", \"B08\"],\n",
    "    output: [{\n",
    "        id: \"truecolor\",\n",
    "        bands: 3\n",
    "        },\n",
    "        {\n",
    "        id: \"ndvi\",\n",
    "        bands: 1,\n",
    "        sampleType: SampleType.UINT16\n",
    "        }\n",
    "    ]\n",
    "  };\n",
    "}\n",
    "\n",
    "function evaluatePixel(sample) {\n",
    "  let ndvi = index(sample.B08, sample.B04);\n",
    "  \n",
    "  let gain = 3.5;\n",
    "  return {\"truecolor\": [gain * sample.B04, gain * sample.B03, gain * sample.B02],\n",
    "         \"ndvi\": [10000 * ndvi + 10000]};\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we returned ndvi as `UINT16` with the following operation: `[10000 * ndvi + 10000]`\n",
    "\n",
    "This trick reduces the size of the returned image, as well as the number of Processing Units used with Sentinel Hub's process API. You can then convert the returned product back to floats by doing: `ndvi_float = (ndvi - 10000.)/10000.`\n",
    "\n",
    "Of course, you can request the NDVI band as `FLOAT32` directly if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set AOI bounding box for our example field and image size according to desired resolution\n",
    "resolution = 10\n",
    "aoi_field = BBox(bbox=field.geometry.bounds.values.tolist()[0], crs=CRS.WGS84)\n",
    "aoi_field_size = bbox_to_dimensions(aoi, resolution=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we create the request body in a loop for both dates and append the `SentinelHubRequest` to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = [\"2017-12-31\", \"2018-11-11\"]\n",
    "requests = []\n",
    "\n",
    "for date in date_list:\n",
    "    requests.append(SentinelHubRequest(evalscript=evalscript_multi_response,\n",
    "                                       input_data=[SentinelHubRequest.input_data(data_collection=DataCollection.SENTINEL2_L2A,\n",
    "                                                                                 time_interval=(date,\n",
    "                                                                                                date))],\n",
    "                                responses=[SentinelHubRequest.output_response('truecolor', MimeType.TIFF),\n",
    "                                           SentinelHubRequest.output_response('ndvi', MimeType.TIFF)],\n",
    "                                bbox=aoi_field,  \n",
    "                                size=aoi_field_size,\n",
    "                                config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the data for both requests\n",
    "t1 = requests[0].get_data()\n",
    "t2 = requests[1].get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the True Color image and NDVI for the two selected dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,14))\n",
    "gs = fig.add_gridspec(2, 2, width_ratios=(20, 20),wspace=0.1, hspace=0.1)\n",
    "\n",
    "# Setup subplots\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax1 = fig.add_subplot(gs[0, 1])\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "\n",
    "# Plot True Color images\n",
    "ax.imshow(t1[0]['truecolor.tif'])\n",
    "ax1.imshow(t2[0]['truecolor.tif'])\n",
    "\n",
    "# Plot NDVI (converting to floats)\n",
    "ndvi_pl = ax3.imshow((t1[0]['ndvi.tif'] - 10000.)/10000., cmap=\"Greens\", vmin=0, vmax=1)\n",
    "ax4.imshow((t2[0]['ndvi.tif'] - 10000.)/10000., cmap=\"Greens\", vmin=0, vmax=1)\n",
    "\n",
    "# Plot configuration\n",
    "for axs in [ax, ax1, ax3, ax4]:\n",
    "    axs.set_xticks([])\n",
    "    axs.set_yticks([])\n",
    "    \n",
    "ax.set_ylabel(\"True Color RGB\")\n",
    "ax3.set_ylabel(\"NDVI\")\n",
    "ax.set_title(\"2017-12-11\")\n",
    "ax1.set_title(\"2018-11-11\")\n",
    "\n",
    "# Setup colorbar\n",
    "axins = inset_axes(ax4, \n",
    "               width=\"5%\",  \n",
    "               height=\"100%\",  \n",
    "               loc='lower left',\n",
    "               bbox_to_anchor=(1.05, 0.0, 1, 1),\n",
    "               bbox_transform=ax4.transAxes,\n",
    "               borderpad=0,\n",
    "               )\n",
    "\n",
    "cb = fig.colorbar(ndvi_pl, cax=axins)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above image shows that it is difficult to differenciate between forest and cultures. The NDVI values are also similar between crops and forest, even though a pattern in the cultivated field is visible. Nevertheless, the values are similar if averaged over the field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of an empirical automated approach\n",
    "\n",
    "Based on the graph of NDVI values over time, we saw that a drop in NDVI doesn't always signify a deforestation event, and can also be linked to harvesting fields. We also saw in the plot above, that it is very difficult to differentiate the NDVi of forest and cultivated deforested parcels. However, the graph showed that the minimum NDVI observed during the dry season is higher for forested areas than for cultivated areas.\n",
    "\n",
    "Based on these observations we will design an algorithm that accounts for the following points:\n",
    "\n",
    "+ We will loop through each available image (with less than 5% cloud cover) in a given period.\n",
    "+ For each image, if the NDVI of the dry season preceding the date is higher than an arbitrary threshold, we consider that the pixel was forested the previous year. \n",
    "+ If the pixel is considered as forested the previous year, we compare the difference in NDVI with the previous date in the time-series, looking for a large drop in NDVI. If we observe a drop (more than an arbitrary threshold), then we assume a deforestation event. However, a pixel can only be deforested once: only the first event in the time series is recorded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will set a time period (three months for this example), then use the Catalog API to fetch the valid images over our area of interest (here the overall area defined at the beginning of the Jupyter Notebook.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set start and end date of each period\n",
    "START_DATE = '2018-01-01'\n",
    "END_DATE = '2018-03-31'\n",
    "\n",
    "# Query the period using Catalog API (if you get a token error, don't forget to request a new token higher up)\n",
    "collections = \"sentinel-2-l1c\"\n",
    "datetime= f\"{START_DATE}T00:00:00Z/{END_DATE}T23:59:59Z\"\n",
    "\n",
    "# Run the catalog request\n",
    "response = oauth.request(\"GET\", f\"https://services.sentinel-hub.com/api/v1/catalog/collections/{collections}/items?bbox={aoi_bbox[0]},{aoi_bbox[1]},{aoi_bbox[2]},{aoi_bbox[3]}&datetime={datetime}&limit=20\", headers=headers)\n",
    "catalog_results = response.json()\n",
    "\n",
    "# Fetch the dates and cloud cover values\n",
    "available_data = []\n",
    "for entry in catalog_results[\"features\"]:\n",
    "    available_data.append((entry[\"properties\"][\"datetime\"], entry[\"properties\"][\"eo:cloud_cover\"]))\n",
    "\n",
    "# Make a list of dates for cloud_cover less than 5%\n",
    "cloud_free_dates = [x[0] for x in available_data if x[1] <= 5]\n",
    "\n",
    "# Reverse to match Evalscript output\n",
    "cloud_free_dates.reverse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following Evalscript, we will request 4 data outputs for each available image in 2018:\n",
    "\n",
    "- B02 (Blue) \n",
    "- B03 (Green) \n",
    "- B04 (Red)\n",
    "- A binary product containing the \"deforested\" pixels (value = 1) for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deforestation_basic_evalscript = \"\"\"\n",
    "//VERSION=3\n",
    "\n",
    "// number of days with a valid image\n",
    "const n_days = {number_days};\n",
    "\n",
    "\n",
    "function setup (){{\n",
    "  // Sentinel Hub's function that prepares inputs/outputs\n",
    "  return {{\n",
    "    input: [\n",
    "      // We need 2 datasources for S2L2A, because we are \n",
    "      // querying 2 different time ranges\n",
    "      {{datasource: \"l2a_winter\", bands:[\"B04\", \"B08\"]}},\n",
    "      {{datasource: \"l2a\", bands:[\"B02\", \"B03\", \"B04\", \"B08\"]}}],\n",
    "    output: [\n",
    "      {{id: \"deforestation_band\", bands: n_days , sampleType: \"UINT8\"}},\n",
    "      {{id: \"B02\", bands: n_days , sampleType: \"UINT16\"}},\n",
    "      {{id: \"B03\", bands: n_days , sampleType: \"UINT16\"}},\n",
    "      {{id: \"B04\", bands: n_days , sampleType: \"UINT16\"}}\n",
    "  ],\n",
    "  mosaicking: \"ORBIT\"\n",
    "  }};\n",
    "}}\n",
    "\n",
    "\n",
    "function evaluatePixel(samples, scenes) {{\n",
    "  // Sentinel Hub's function that processes the data\n",
    "  \n",
    "  var S2L2A_scenes = scenes.l2a.scenes;\n",
    "  var L2AW = samples.l2a_winter;\n",
    "  var S2L2A = samples.l2a;\n",
    "\n",
    "  // 1. Calculate the average NDVI in the winter of the previous year\n",
    "  var ndvi = 0;\n",
    "\n",
    "  for (var i = 0; i < L2AW.length; i++) {{\n",
    "    ndvi += index(L2AW[i].B08, L2AW[i].B04);\n",
    "  }}\n",
    "\n",
    "  var avg_ndvi = ndvi / L2AW.length;\n",
    "    \n",
    "  // 2. Run through all the dates in 2018 and detect deforestation events\n",
    "\n",
    "  //  Initialise data\n",
    "  var cloudless_bands = {{'B02':new Array(n_days).fill(0),\n",
    "                         'B03':new Array(n_days).fill(0),\n",
    "                         'B04':new Array(n_days).fill(0),\n",
    "                         'representation':new Array(n_days).fill(0)}};\n",
    "                         \n",
    "  var count = 0;\n",
    "  var deforestation_sum = 0;\n",
    "  var deforestation = [];\n",
    "\n",
    "  for (var j = S2L2A.length-2; j >= 0; j--){{\n",
    "    if (index(S2L2A[j+1].B08, S2L2A[j+1].B04) - index(S2L2A[j].B08, S2L2A[j].B04) > 0.2){{\n",
    "      if (avg_ndvi >= 0.35 && deforestation_sum == 0 && index(S2L2A[j].B08, S2L2A[j].B04) < 0.4){{\n",
    "        deforestation.push(1);\n",
    "        deforestation_sum += 1;\n",
    "      }} else {{\n",
    "        deforestation.push(0);\n",
    "      }}\n",
    "    }} else{{\n",
    "      deforestation.push(0);\n",
    "    }}\n",
    "    // Fill bands with data\n",
    "    cloudless_bands['B02'][count] = S2L2A[j].B02 * 65535;\n",
    "    cloudless_bands['B03'][count] = S2L2A[j].B03 * 65535;\n",
    "    cloudless_bands['B04'][count] = S2L2A[j].B04 * 65535;\n",
    "    \n",
    "    count += 1;\n",
    "  }}\n",
    "  \n",
    "\n",
    "  return {{\"deforestation_band\": deforestation,\n",
    "          \"B02\": cloudless_bands.B02,\n",
    "          \"B03\": cloudless_bands.B03,\n",
    "          \"B04\": cloudless_bands.B04}};\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the follwing cell we build the request, and run it, saving the results to a file, since we want to open the files with rasterio to vectorise the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = SentinelHubRequest(\n",
    "  evalscript=deforestation_basic_evalscript.format(number_days=len(cloud_free_dates)-1),\n",
    "  input_data=[\n",
    "    SentinelHubRequest.input_data(\n",
    "      data_collection=DataCollection.SENTINEL2_L2A,\n",
    "      time_interval=(START_DATE, END_DATE),        \n",
    "      other_args = {\"dataFilter\":{\"maxCloudCoverage\":\"5\"},\"id\":\"l2a\"}\n",
    "    ),\n",
    "    SentinelHubRequest.input_data(\n",
    "      data_collection=DataCollection.SENTINEL2_L2A,\n",
    "      time_interval=('2017-08-01', '2017-10-01'),        \n",
    "      other_args = {\"dataFilter\":{\"maxCloudCoverage\":\"5\"},\"id\":\"l2a_winter\"}\n",
    "    ),\n",
    "    \n",
    "  ],\n",
    "  responses=[\n",
    "    SentinelHubRequest.output_response('deforestation_band', MimeType.TIFF),\n",
    "    SentinelHubRequest.output_response('B02', MimeType.TIFF),\n",
    "    SentinelHubRequest.output_response('B03', MimeType.TIFF),\n",
    "    SentinelHubRequest.output_response('B04', MimeType.TIFF),\n",
    "    \n",
    "  ],\n",
    "  bbox=aoi_overview,  \n",
    "  size=aoi_overview_size,\n",
    "  data_folder='./results/deforestation',\n",
    "\n",
    "  config=config\n",
    ")\n",
    "response = request.get_data(save_data=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response is stored as a tar, so we need to decompress it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch folder created in the destination directory\n",
    "fld_d = [f for f in Path(\"./results/deforestation/\").iterdir() if f.is_dir()][0]\n",
    "\n",
    "# Extract the tar file\n",
    "with tarfile.open(fld_d.joinpath(\"response.tar\") , 'r') as tar:\n",
    "    tar.extractall(path=fld_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the automatically detected deforested areas on the RGB image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For easier plotting we will define a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fields_RGB(r, g, b, fields, t=0, gain=2, alpha=0.5, title=None):\n",
    "    \n",
    "    rgb_stack = np.stack((r[:,:,t], g[:,:,t], b[:,:,t]), axis=2)\n",
    "    deforested_plots = np.ma.masked_where(fields[:,:,t] == 0, fields[:,:,t])\n",
    "\n",
    "\n",
    "    # make a color map of fixed colors\n",
    "    cmap = colors.ListedColormap(['red'])\n",
    "    bounds=[1]\n",
    "    norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20,20))\n",
    "    ax.imshow(rgb_stack * gain)\n",
    "    ax.imshow(deforested_plots, cmap=cmap, norm=norm, interpolation='none', alpha=alpha)\n",
    "    \n",
    "    # Plot configuration\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    patches = [mpatches.Patch(color=\"red\", label=\"Deforested area\", alpha=0.9)]\n",
    "    plt.legend(handles=patches, loc=2)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are running a per-pixel analysis in the Evalscript, noise may appear in the results. We have defined a function in the cell below that allows us to remove spurious pixels and return a \"cleaner\" result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean deforestation band\n",
    "def erode_dilate(array, size, dim=0):\n",
    "    \n",
    "    if dim >= 1:\n",
    "        er = morphology.grey_erosion(array, size=(size, size, dim))\n",
    "        dil = morphology.grey_dilation(er, size=(size, size, dim))\n",
    "    else:\n",
    "        er = morphology.grey_erosion(array, size=(size, size))\n",
    "        dil = morphology.grey_dilation(er, size=(size, size))\n",
    "    \n",
    "    \n",
    "    return dil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the responses from the returned variable and assign them to individual variables\n",
    "# The division by 65535 converts the UINT16 DN back to Reflectance\n",
    "B02 = response[0]['B02.tif'] / 65535\n",
    "B03 = response[0]['B03.tif'] / 65535\n",
    "B04 = response[0]['B04.tif'] / 65535\n",
    "\n",
    "# Clean the deforested array \n",
    "deforest_raster = erode_dilate(response[0][\"deforestation_band.tif\"], 3, dim=1)\n",
    "\n",
    "# Free the returned variavle from our SentinelHub request\n",
    "response = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can plot the data in the next cell. In the function below, `t` corresponds to the time slice, `gain` to the multiplication factor of the RGB image for visualisation, and we fetch the time step from the catalog API (the date corresponds to `t` + 1, since we skip the first timestep in the Evalscript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the RGB image for a date with the raster\n",
    "plot_fields_RGB(B04, B03, B02, deforest_raster, t = 0, gain=3, title=cloud_free_dates[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert results to polygons\n",
    "\n",
    "Now that we have saved the binary `deforestation` raster locally, we can use `rasterio` to convert the raster to polygons, in order to update the database that we queried at the start of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the deforestation band\n",
    "deforestation_raw = []\n",
    "deforestation_cleaned = []\n",
    "\n",
    "with rasterio.open(fld_d.joinpath(\"deforestation_band.tif\")) as dataset:\n",
    "    # Loop over bands\n",
    "    for bnd in range(dataset.count):\n",
    "        dataset_band = dataset.read(bnd+1)\n",
    "       \n",
    "        # Clean the polygons with an erosion / dilation step\n",
    "        clean_defor = erode_dilate(dataset_band, 3)\n",
    "        \n",
    "        # Calculate polygons from both cleaned and raw rasters\n",
    "        raw_shapes = list(rasterio.features.shapes(dataset_band,\n",
    "                                                   transform=dataset.transform))\n",
    "        clean_shapes = list(rasterio.features.shapes(clean_defor,\n",
    "                                                     transform=dataset.transform))\n",
    "\n",
    "        raw_polygons = [shape(geom) for geom, value in raw_shapes if value == 1]\n",
    "        clean_polygons = [shape(geom) for geom, value in clean_shapes if value == 1]\n",
    "\n",
    "        # Make a multipolygon and conver to GeoSeries\n",
    "        deforestation_raw.append(geopandas.GeoSeries(unary_union(raw_polygons)))\n",
    "        deforestation_cleaned.append(geopandas.GeoSeries(unary_union(clean_polygons)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the polyons from the first time step to see how the cleaning step performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(18,12))\n",
    "\n",
    "deforestation_raw[0].plot(ax=ax, color=\"red\", label=\"Raw deforestation detection band\")\n",
    "deforestation_cleaned[0].plot(ax=ax, color=\"black\", label=\"Cleaned deforestation detection band\")\n",
    "\n",
    "# Plot configuration\n",
    "ax.set_xlim(-60.20, -60.26)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot above, the raw deforestation polygons are plotted in red and the cleaned polygons in black. The erosion dilation step removes a lot of individual scattered pixels, but is a little too \"agressive\" in some of the plots. Nevertheless, most fields are correctly represented and noise is removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Looping the loop\": adding the polygons back into a dataframe\n",
    "\n",
    "Now we have a set of polygons representing deforestation, we can add them into our existing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a geopandas with our polygons\n",
    "rdf = geopandas.GeoDataFrame(pd.concat(deforestation_cleaned, ignore_index=True) )\n",
    "\n",
    "# Add metadata\n",
    "rdf[\"pais\"] = \"Paraguay\"\n",
    "rdf[\"prov_dep\"] = \"BoquerÃ³n\"\n",
    "rdf[\"date\"] = [x.split(\"T\")[0] for x in cloud_free_dates[1:]]\n",
    "\n",
    "# Rename the geometry column\n",
    "rdf.rename(columns={0: 'geometry'}, inplace=True)\n",
    "\n",
    "# Show the created geopandas\n",
    "rdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a correctly formatted `geopandas` Dataframe, we can append it to the database that we queried at the start of this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gran_chaco_updated = gran_chaco.append(rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the updated dataframe\n",
    "gran_chaco_updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we only filled out basic information, in the previous steps, you can calculate more of the parameters listed in the table. For now, let's compare the polygons in the original dataset, with those in the updated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18,12))\n",
    "\n",
    "# Plot  datasets\n",
    "gran_chaco.plot(ax=ax)\n",
    "gran_chaco_updated.plot(ax=ax2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have detected more deforestation events in February and March 2018, a promising result. To share the dataset using geoDB, please refer to the free tutorial Jupyter Notebooks in the Marketplace.\n",
    "\n",
    "As mentioned earlier, this basic approach is empirical and may not be robust for different areas/time of year. The goal was to get you started in creating your own scripts, and we hope to see new exciting algorithms in EDC..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EDC 0.22.3 (Python3)",
   "language": "python",
   "name": "edc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
